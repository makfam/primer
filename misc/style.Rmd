---
title: "Style Guideline"
author: "David Kane"
date: "5/9/2020"
output: html_document
---

* Never use just a single `#` after using it for the chapter title. The first subpart uses a `##`. There should be 5 to 8 subparts for each chapter. Within each subpart, you may have sub-subparts, indicated with `###`. There should be 3 to 10 of those. You may use `####` if you like.

* Section headings (other than Chapter titles) are in sentence case (with only the first word capitalized, unless it is something always capitalized) rather than title case (in which all words except small words like "the" and "of" are capitalized). Chapter titles (Building Models) are in title case. Headings do not end with a period.

* Never hard code stuff like "A tibble with 336,776 rows and 19 columns." What happens when you update the data? Instead, calculate all numbers on the fly, with `r scales::comma(x)` whenever x is a number in the thousands or greater.  Example: "A tibble with `r scales::comma(nrow(x))` rows and `r ncol(x)` columns."

* "We" are writing this book. 

* Package names are in bold: **ggplot2** is a package for doing graphics.

* R code, anything you might type in the console, is always within backticks. Example: `mtcars` is a built-in dataset.

* Function names always include the parentheses: we write `pivot_wider()`, not `pivot_wider`.

* Do not use code chunk names because it messes up building the book because of limits in **bookdown**.

* All tables should be created with the **gt** package. 

* All images and gifs are loaded with `knitr::include_graphics().`

* Only code chunk options allowed are include = FALSE, echo = FALSE, fig.cap = "This is my cap" and message = FALSE when loading packages like ggplot2 since it prevents all the messages from printing out.

* Interim data sets should be called `x` or something sensible to the situation, like `ch7` for a data set you are working with in Chapter 7. Do not use names like `data` and `df`, both of which are R commands.

* There are no length restrictions in the book, so never do too much code in a single step. Show the results of each step. Show what each column (mod, data, etc) looks like as it is added to the tibble.


## What is the Problem?

* Add lots of memes and videos and cartoons.

Every chapter 5+ begins with a problem, and the decision we must make. These are often toy, highly stylized problems. The decisions are not realistic. But, in structure, these problems parallel the real problems that people face, the actual decisions which they must make.

The problem is specified at the end of the "preamble," the untitled part of the chapter after the title and before the first subpart. Example from Chapter 8:

> A person arrives at a Boston commuter station. The only thing you know is their political party. How old are they? Two people arrive: A Democrat and a Republican. What are the odds that the Democrat is 10% older than the Republican?

> A different person arrives at the station. You know nothing about them. What will their attitude toward immigration be if they are exposed to Spanish-speakers on the platform? What will it be if they are not? How certain are you? 

Is this an actual problem that someone might face? No! But it is like such problems. The first requires the creation of a predictive model. The second necessitates a causal model. The rest of the chapter teaches the reader how to create such models. The end of the chapter harkens back to the questions from the beginning.

Might it be nice to put more meat on the story than that? Perhaps. In an ideal world, the "decision" you faced would be more complex than just playing the prediction game. Begin with a decision. What real world problem are you trying to solve? What are the costs and benefits of different approaches? What unknown thing are you trying to estimate? With Sampling, it might be: How many people should I call? With estimating one parameter --- like vote share as the ballots come in --- it might be: How much should I bet on the election outcome? 

The data we have might not be directly connected to our problem. For example, we might be running a Senate campaign and trying to decide what to spend money on. The Spanish-speakers-on-a-train-platform data set is not directly related to that problem, but it isn't unrelated. Indeed, the first theme of "valadity" is directly related to this issue: Is the data we have relevant to the problem we want to solve? (Tukey quote about some data and a burning desire to answer the question being enought.)

Yet, this seems a bridge too far for the summer of 2020, although we might revisit. For now, the start of each chapter asks a question which is a simple application of the prediction game. 


## Recommendations

* Make ample use of comments, placed with the handy CMD-Shift-/ shortcut. These are notes for everyone else working on the chapter, and for future you.

* At the start of the chapter:
  + Create a list of all packages used. List just **tidyverse**, not all the sub-packages. Almost every chapter will use **tidyverse** and **primer.data**.
  + Create a list of every new command that the chapter introduces. This will help us in creating the tutorial for that chapter. You can also include commands which, while perhaps not new, are important.
  + List the packages and commands that you are thinking of including.
  + List the datasets which will be used. With luck, all of these will come from the primer.data.

* Students are sometimes tentative. Don't be! Edit aggressively. If you don't like what is there, delete it. (If I disagree with your decision, I can always get the text back from Github.) Move things around. Make the chapter yours, while keeping to the style of the other chapters. Note that 90% of the prose here was not written by me. As the Acknowledgment page explains, the book is currently a collection from different open-sourced textbooks. Cut anything you don't like.

* If you make an mp4, you can convert it to .gif using https://convertio.co/mp4-gif. 

* Use `include_graphics()` for images and gifs.

* Everything is Bayesian. The confidence interval for a regression means that there is a 95% chance that the true value lies within that interval. Use Rubin Causal Model and potential outcomes to define precisely what "true value" you are talking about. And so on.


## Open Questions

* Use tidybayes package for better graphics throughout? 

* Look at the **flair** package to format the code. Or does that require us to have two copies of code: working copy and colored copy? https://education.rstudio.com/blog/2020/05/flair/

* Does using **flipbookr** make sense in the middle of a chapter?

* https://github.com/yonicd/carbonate -- perhaps useful for some nicer formatting of source code.




