# N Parameters {#n-parameters}

<!-- Two goals this week: -->

<!-- First, replace geom_pointrange with appropriate functions from ggdist. https://mjskay.github.io/ggdist/ Do not use tidy(). Start with 


fit_1 %>% 
  as_tibble() %>% 
  pivot_longer(cols = stateAlabama:stateWyoming,
               names_to = "state",
               values_to = "years") %>% 
  mutate(state = str_replace(state, "state", "")) %>%              
  ggplot(aes(x = vals, y = pulls)) +
  
  # Not these geoms. I think we just want pointinterval
  
  stat_halfeye(aes(fill = stat(cut_cdf_qi(cdf, .width = c(0.95, 1)))),
               show.legend = FALSE) +
  scale_fill_calc()


-->


<!-- Second, make shaming part of chapter good! Population, temperance, Preceptor's Posterior, ideal Preceptor Table, testing. All the cool themes. Bring it all together. Make the students say Ahhh! -->

<!-- Where is the question that we are trying to answer? Do we answer them? Are they good questions? -->

<!-- Example: No discussion of population, validity, representativeness or ethics in Wisdom discussion. -->

<!-- * Should start with  single variable which actually requires lots of parameters. For example, death_age as a function of state and come up with a different average death_age for each state. This is cheating in that it is too many parameters, or rather that some of the parameters need to be estimated for too little data.  But it would allow us to explain a bunch of stuff! Including Bayesian shrinkage. Saving this till the end of the model causes us to miss stuff. But the rest of the analysis used lived_after. Which is better. Yes? Should we discuss? Use both? -->


<!-- Consider getting rid of state example, or moving it as a teaser to end of chaoter 10. Could we make a similar point with an example from shaming? -->

*This chapter is still a DRAFT.*

Having created models with one parameter in Chapter \@ref(one-parameter), two parameters in Chapter \@ref(two-parameters), three parameters in Chapter \@ref(three-parameters), four parameters in Chapter \@ref(four-parameters) and five parameters in Chapter \@ref(five-parameters), you are now ready to make the jump to $N$ parameters. 

In this chapter, we will consider models with many parameters and the complexities that arise therefrom. 


## More on candidate longevity

Let's continue our examination of the longevity of gubernatorial candidates which we began in Chapter \@ref(five-parameters). Recall the packages we need and the tibble we created:

```{r, message = FALSE}
library(tidyverse)
library(primer.data)
library(rstanarm)
library(ggdist)

ch11 <- governors %>% 
  select(last_name, year, state, sex, lived_after, election_age) %>% 
  drop_na()
```

<!-- DK: Might discover that people who ran more than once are listed more than once. Or save that for Chapter 12. -->

### state

Consider a model in which years lived after the election is a function of the state in which the candidate lives. This assumption generates a model with 51 parameters, one average value for each state and the residual variance. By excluding an intercept, we give the parameters an easier interpretation. With an intercept, the interpretation for each of the other $\beta$'s would be as the difference in expected age relative to the first state. 

Mathematics:


$$ lived\_after_i =  \beta_1 x_{AL,i} + \beta_2 x_{AK,i} + ... + \beta_{49} x_{WI,i}  + \beta_{50} x_{WY,i} + \epsilon_i$$
As usual, $\epsilon_i \sim N(0, \sigma^2)$. Conceptually, this model is identical to several of the three parameter models we explored in Chapter \@ref(three-parameters). For an individual candidate, the years to live after the election are function of the average for her state and of an error term. None of the other coefficients matter because the indicator variables are zero for all the other states. For example, the model for a candidate from Alaska simplifies to:

<!-- DK: Make these all line up nicer? -->

$$ lived\_after_i =  \beta_1 x_{AL,i} + \beta_2 x_{AK,i} + ... + \beta_{49} x_{WI,i}  + \beta_{50} x_{WY,i} + \epsilon_i $$
$$ lived\_after_i =  \beta_1 0 + \beta_2 1 + ... + \beta_{49} 0  + \beta_{50} 0 + \epsilon_i $$
$$ lived\_after_i =   \beta_2  + \epsilon_i $$
The interpretation is the same as when we modeled `age` as a function of `party` or `att_end` as a function of `treatment` in Chapter \@ref(three-parameters). (Review those sections if this is unclear.) In all these cases, an individual can only be in one category. She can be a Democrat or a Republican. She can received the treatment or not. She can live in Alabama or Alaska or . . . . The only wrinkle we have added is that there are 50 categories under consideration, not just two.

The code is exactly the same as in those Chapter \@ref(three-parameters) examples.

```{r}
fit_1 <- stan_glm(formula = lived_after ~ state - 1,
                  data = ch11,
                  refresh = 0,
                  seed = 76)
```

We do not need to, explicitly, tell R that there are 50 categories. It determines that from `state`, just as it determined that there were two possibilities for `treatment`. The difficulty arises, however, when we try to examine the parameter values:

```{r}
fit_1
```

That is a lot to take in! Examining and comparing two parameters --- the average attitude toward immigration of the treated and control, for example --- is easy. Doing the same for 50 parameters is hard. The **broom** and  **broom.mixed** packages were created to make this problem easier to manage, for all sorts of statistical models. For **rstanarm** models, we need the latter:

```{r, message = FALSE}
library(broom.mixed)
```

`tidy()` is the key function.

```{r}
fit_1_params <- tidy(fit_1)

fit_1_params
```

Putting all the parameters into a tibble makes everything much easier  to interpret. For example, we can look at the states with the longest and shortest lived candidates:

```{r}
fit_1_params %>% 
  arrange(desc(estimate)) %>% 
  slice(1:5, 46:50)
```
 
 <!-- DK: Going forward, would you expect candidates from Delaware to live 14 years longer than candidates from Wyoming? Discuss what these terms mean. -->
 
<!-- DK: Should change this to use the ggdist package. -->
 
A graphical display is the best way to examine numerous parameters at the same time.  


```{r, fig.height = 8}
fit_1_params %>% 
  mutate(state = str_replace(term, "state", "")) %>% 
  ggplot(aes(x = fct_reorder(state, estimate),
             y = estimate)) +
    geom_pointrange(aes(ymin = estimate - 2 * std.error,
                        ymax = estimate + 2 * std.error)) +
    coord_flip() +
    labs(title = "Expected Years Lived Post Election",
         y = "Years",
         x = NULL)


```


This is a lot to take in! If this looks overwhelming, don't worry. Rather than our normal maximum of five parameters, we are looking at 51 parameters here, an average for 50 states and $\sigma$. This is a big leap, and it is hard to absorb this much information at once. 

As data scientists, the first question we must ask ourselves is whether or not we believe this data. Do we really expect the next candidate elected in Delaware to live significantly longer than the next candidate elected in Wyoming, or any other state? No! Of course not. We are modeling a relationship, but we cannot possibly claim that living in Delaware or Wyoming causes an increase or decrease in lifespan. 

One possible explanation is that Wyoming tends to elect older candidates, which makes the years lived post-election smaller. Another possible explanation is that a few outliers --- perhaps a candidate that died shortly after the election or a young candidate that lived an exceptionally long time after the election --- are making the differences between the lowest and highest states more drastic. Yet another explanation could be that we have more observations for certain states, as compared to other states. The point we are making is: this is an interesting plot, but it is not **the truth**. 


<!-- DK: Switch above to using ggdist. -->

<!-- DK: Add a sensible discussion about whether or not we believe this.  MF: Done. -->

<!-- DK: In the next draft if this chapter, we ought to use a different data set which illustrates Bayesian shrinkage. Alas, does not work for this data because all the states have about the same number of observations. -->

### state, election_age, sex and election_age*sex

Let's consider another model for $lived\_age$, one which adds `state` to the model we used at the end of the previous chapter. 

Math:


$$ lived\_after_i =  \beta_0 +  \beta_1 x_{AK,i} + \beta_2 x_{AR,i} + ... \beta_{49} x_{WY,i} + \\
\beta_{50} male_i + \beta_{51} election\_age_i+ \beta_{52} male_i *  election\_age_i + \epsilon_i$$

<!-- DK: Clean this up. Explain meaning of intercept more clearly. -->

*  $lived\_after_i$ is the outcome variable. 

* $\beta_1$, $\beta_2$, $\beta_3$... all the way to $\beta_{49}$ correspond to different parameters. These values are specific to each state. In order to find the female intercept (i.e. lived_after for females) for a specific state, you must add that state's beta value to the value of $\beta_0$. The resulting value provides you with the intercept for the `lived_after` outcome for females candidates in that specific state. For example, if you look at the model above, $\beta_1$ is the intercept value for Arkansas (note the AK subscript). You would take the appropriate value, which appears next to Arkansas in the printed model, and add it to the value for $\beta_0$.

* $\beta_0$ will be the intercept for one state alone. When the model is printed, you will see that (Intercept) takes on the lived_after value for female candidates in Alabama. 

* $\beta_{50}$ is the coefficient for the explanatory variable $male_i$. When we are trying to find the intercepts for female candidates, the explanatory variable will take on the value of 0. However,  $male_i$ = 1 when we are trying to find intercept values for male candidates. Therefore, to find the intercept value for male candidiates, there is an additional step: we add the $\beta_{50}$ value to the female intercept value.

* $\beta_{51}$ is the coefficient for the explanatory variable $election\_age_i$. It is just the slope for women. 

* $\beta_{52}$ is difficult to interpret. However, it gains meaning when it is added to $\beta_{51}$, which results in the slope for men.

<!-- DK: Missing stuff here! -->
 

```{r, cache = TRUE}
fit_gov_1 <- stan_glm(data = ch11,
                      formula = lived_after ~ state + sex*election_age,
                      refresh = 0,
                      iter = 10000,
                      seed = 98)
```

Note that this takes awhile to run since we are dealing with 55 parameters here.

<!-- DK: How do we not print out all the coefficients? -->

```{r}
print(fit_gov_1, detail = FALSE)
```

The (Intercept) refers to the average number of years lived after the election for women from Alabama, who on the day of election, have been alive the average number of years of all female candidates! That's a mouthful. It really is not different than what we have been doing all along, however. You can see here that (Intercept) value is around `r round(coef(fit_gov_1)["(Intercept)"], 0)` years. 

Thus far, we have only talked about female values. What about the male values? Well, if you look at the bottom of the list, you will see the `sexMale` value of around `r round(coef(fit_gov_1)["sexMale"], 0)`. When you wish to estimate `lived_after` for a specific state *for male candidates*, you must add this value to the intercept, and then also add the intercept of the desired state. 

$\beta_{51}$, our coefficient value for $election\_age_i$, is `r round(coef(fit_gov_1)["election_age"], 2)`. When comparing female candidates who differ by one year in their current ages, there is not much of a difference in how many years we expect them to live after the election.

<!-- DK: Conflict between $election\_age_i$ and `sexMale:election_age`. Which is better? Should be consistent. -->

$\beta_{51} + \beta_{52}$, our coefficients for $election\_age_i$ and `sexMale:election_age`, results in the value of around `r round(coef(fit_gov_1)["election_age"] + coef(fit_gov_1)["sexMale:election_age"], 1)`. This value is our slope for men.


<!-- DK: This is a mess! -->

<!-- Posterior distribution for female candidates in Washington and South Dakota.  -->

<!-- DK: Clean up math here. No hard coding numbers!-->

<!-- ```{r} -->
<!-- fit_gov_1 %>%  -->
<!--   as_tibble() %>%  -->
<!--   mutate(Washington_females = `(Intercept)` + stateWashington) %>%  -->
<!--   mutate (SD_females = `(Intercept)` + `stateSouth Dakota`) %>%  -->
<!--   select(Washington_females, SD_females) %>%  -->
<!--   pivot_longer(cols = Washington_females:SD_females,  -->
<!--                names_to = "parameters", -->
<!--                values_to = "years") %>%  -->
<!--   ggplot(aes(years, fill = parameters)) + -->
<!--     geom_histogram(aes(y = after_stat(count/sum(count))), -->
<!--                    alpha = 0.5,  -->
<!--                    bins = 100,  -->
<!--                    position = "identity") + -->
<!--     labs(title = "Posterior Probability Distribution", -->
<!--          subtitle = "for women that live in Washington and South Dakota", -->
<!--          x = "Average Years Lived Post Election", -->
<!--          y = "Probability") +  -->
<!--     scale_x_continuous(labels = scales::number_format()) + -->
<!--     scale_y_continuous(labels = scales::percent_format()) + -->
<!--     theme_classic() -->
<!-- ``` -->


<!-- The posterior above shows that female candidates in Washington live longer after the election than female candidates in South Dakota. Interesting huh? Our knowledge about averages is always more precise than our knowledge about individuals.  -->



<!-- DK: Need to modify this to only show one of the more interesting state coefficients. (Although we might show all the state pdfs in the graphic.) This a good place to discuss shrinkage, which is what is happening here. And that is probably enough models. -->


## Wisdom

```{r echo = FALSE, fig.cap = "Wisdom"}
knitr::include_graphics("other/images/Wisdom.jpg")
```

Imagine you are running for Governor and want to do a better job of getting your voters to vote. You recently read about a large-scale experiment showing the effect of sending out a voting reminder that "shames" citizens who do not vote. You are considering sending out a "shaming" voting reminder yourself. 

Our questions are: **What will happen if we do send a voting reminder? Will more voters show up to the polls? Additionally, on the day of the election, a female citizen is randomly selected. What is the probability she will vote?** 


### EDA of `shaming`

Consider a new data set, `shaming`, corresponding to an experiment carried out by Gerber, Green, and Larimer (2008) titled "Social Pressure and Voter Turnout: Evidence from a Large-Scale Field Experiment". This experiment used several hundred thousand registered voters and a series of mailings to determine the effect of social pressure on voter turnout. 

Let's now do another EDA, starting off by running `glimpse()`.

```{r}
library(primer.data)
library(tidyverse)
library(skimr)
glimpse(shaming)
```

We see that `glimpse()` gives us a look at the raw data contained within the `shaming` data set. At the very top of the output, we can see the number of rows and columns, or observations and variables respectively. We see that there are 344,084 observations, with each row corresponding to a unique respondent. This summary provides an idea of some of the variables we will be working with. 

Variables of particular interest to us are `sex`, `hh_size`, and `primary_06`. The variable `hh_size` tells us the size of the respondent's household, `sex` tells us the sex of the respondent, and `primary_06` tells us whether or not the respondent voted in the 2006 Primary election. 
There are a few things to note while exploring this data set. You may -- or may not -- have noticed that the only response to the `general_04` variable is "Yes". In their published article, the authors note that "Only registered voters who voted in November 2004 were selected for our sample" (Gerber, Green, Larimer, 2008). After this, the authors found their history then sent out the mailings. Thus, non-registered voters are excluded from our data.

It is also important to identify the dependent variable and its meaning. In this shaming experiment, the dependent variable is `primary_06`, which is a variable coded either 0 or 1 for whether or not the respondent voted in the 2006 primary election. This is the dependent variable because the authors are trying to measure the **effect** that the treatments have on voting behavior in the 2006 general election.

<!-- HV: Should I include discussion of the left-hand variable (treatment?) here? Or wait until we move into the regressions? -->

We have not yet discussed the most important variable of them all: `treatment`. The `treatment` variable is a factor variable with 5 levels, including the control. Since we are curious as to how sending mailings affects voter turnout, the treatment variable will tell us about the impact each type of mailing can make. Let's start off by taking a broad look at the different treatments.

<!-- HV: Is it okay to say the first sentence of this paragraph? -->

```{r}
shaming %>%
  count(treatment)
```

Four types of treatments were used in the experiment, with voters receiving one of the four types of mailing. All of the mailing treatments carried the message, "DO YOUR CIVIC DUTY - VOTE!". 

The first treatment, Civic Duty, also read, “Remember your rights and responsibilities as a citizen. Remember to vote." This message acted as a baseline for the other treatments, since it carried a message very similar to the one displayed on all the mailings.

In the second treatment, Hawthorne, households received a mailing which told the voters that they were being studied and their voting behavior would be examined through public records. This adds a small amount of social pressure to the households receiving this mailing.

In the third treatment, Self, the mailing includes the recent voting record of each member of the household, placing the word "Voted" next to their name if they did in fact vote in the 2004 election or a blank space next to the name if they did not. In this mailing, the households were also told, “we intend to mail an updated chart" with the voting record of the household members after the 2006 primary. By emphasizing the public nature of voting records, this type of mailing exerts more social pressure on voting than the Hawthorne treatment.

The fourth treatment, Neighbors, provides the household members' voting records, as well as the voting records of those who live nearby. This mailing also told recipients, "we intend to mail an updated chart" of who voted in the 2006 election to the entire neighborhood.

For now, let's focus on a subset of the data. We will sample just 10,000 rows because otherwise `stan_glm()` takes an annoyingly large amount of time to work. Nothing substantive changes.

```{r}
set.seed(9)
ch9_sham <- shaming %>% 
  filter(treatment %in% c("Control", "Neighbors")) %>% 
  droplevels() %>% 
  mutate(solo = ifelse(hh_size == 1, TRUE, FALSE)) %>% 
  select(primary_06, treatment, solo, sex, age) %>% 
  slice_sample(n = 10000, replace = FALSE)
```

We create the variable `solo`, which is TRUE for voters who live alone and FALSE for those that do not. We are curious to see if the treatment effect, if any, is the same for voters who live alone as it is for those who do not. We have also focused in on only two "treatments": Control and Neighbors. This is for the sake of simplification. We want to know if social pressure impacts voting behavior, so it makes sense to look at the treatment that provides the most social pressure. 

```{r}
ch9_sham %>% 
  skim()
```


Let's focus on a few observations that may be relevant to our analysis. First, note that each treatment has approximately 38,000 respondents. The control group, denoted by `Con`, has approximately 190 thousand respondents. For the logical variable `solo`, we see that approximately 47 thousand of the total respondents live alone (TRUE), while approximately 296 thousand live in households greater than 1 (FALSE). It may also be important to note that the average age of the respondents is 49.8 years with a standard deviation of 14.4 years.

### Population

One of the most important components of Wisdom is the concept of the "population". Recall the questions we asked earlier:

*What will happen if we do send a voting reminder today? Will more voters show up to the polls? Additionally, on the day of the election, a female citizen is randomly selected. What is the probability she will vote?*

As we have discussed before, the population *is not* the set of people, or voters, for which we have data. This is the dataset. The population is the larger --- potentially much larger --- set of individuals about whom we want to make inferences. 

There are many different populations, each with its own $\mu$, in which we might be interested. For instance:

* The population for registered voters that voted in the 2004 election in the United States. This is the population for our dataset. 
* The population for registered voters that voted in any election from 1970 to 2040. We are often interested in the future. We want to make predictions about what *will* happen to voter habits, not what has already happened. 
* The population for registered **and** non-registered voters in the United States. Though it is helpful to look at registered voters, candidates also want to get non-registered voters to vote for them!
* The population for voters --- registered or not-registered --- around the world. We might expect the habits of Americans to be similar to the habits of people in other countries. We might also believe that this is too broad a group to make inferences about.
* Many more!

In this case, we are viewing the data from the perspective of someone running for Governor this year that wants to increase voter turnout. We want to increase turnout **now**, not for people voting in 2006! We also may want to increase turnout in those citizens who are not registered to vote, a group that is excluded from our dataset. Is it reasonable to generate conclusions for this group? Most likely, no. However, we have limited data to work with and we have to determine how far we are willing to generalize to other groups. 

It is a judgment call, a matter of Wisdom, as to whether or not that data we have is “close enough” to the population we are interested in to justify making a model.

Even though the original question is about “voters” in general, and does not specifically refer to specific states in which we might be interested, we will assume that the data we have for random voters is, uh, representative enough of the population we are interested in. If we did not believe that, then we should stop right now. *The major part of Wisdom is deciding what questions you can’t answer because of the data you just don’t have.*

<!-- DK: Add discussion of what you see here. No need to drop missing values since there aren't any. I think this next discussion can be dropped. -->

<!-- DK: Note that this situation is different from Chapter 8 in that fitted values and predicted values are not the same thing! The fitted value, for a combination of values for treatment and solo, is something 0.30, meaning that 30% of the people in this bucket votes. But the predicted value must be 0 or 1. Either you voted or you didn't. This example is clearly causal and so you need a Rubin Table with 5 potential outcome columns. The key difference in this chapter is that we are using lots of right hand side variables, both continuous and discrete. -->


## Justice and Courage

```{r echo = FALSE, out.width="60%", fig.align='center', fig.cap = "Justice"}
knitr::include_graphics("other/images/Justice.jpg")
```

```{r echo = FALSE, out.width="60%", fig.align='center', fig.cap = "Courage"}
knitr::include_graphics("other/images/Courage.jpg")
```

Because we will be going through a series of models in this chapter, it is useful to combine the virtues of Justice and Courage. To begin, let's model `primary_06`, which represents whether a citizen voted or not, against age and treatment to see if there is a connection. 

### primary_06 ~ treatment + age

<!-- What should the Preceptor tables look like with these models? Like chapter 3. Should each model have its own Preceptor Table? No! Just one preceptor table at the start, with 5 columns under Y, and 4 covariates, where one is treatment assigned. -->

In this section, we will look at the relationship between primary voting and treatment + age. Note that `treatment` is a categorical explanatory variable and `age` is a continuous explanatory variable. This is the same type of model --- parallel slopes --- as we saw in Chapter \@ref(four-parameters).

The math:

$$ primary\_06_i =  \beta_0 + \beta_1 treatment_i + \beta_2 age_i + \epsilon_i $$

How do we interpret this?

* The outcome variable is $primary\_06_i$, which represents whether someone voted in the 2006 primary election or not. 
* $treatment_i$ is one of our explanatory variables. If we are predicting the voting behavior of someone under treatment, this value will be 1. When we are making this prediction for those in the control group, this value will be 0. 
* $age_i$ is our other explanatory variable. It is the number of years a voter has lived at the time of the election.
* * $\beta_0$ is the voting percentage for those in the control group, who on the day of election, have been alive for 0 years of age. Clearly, age is nonsensical in this paradigm. $\beta_0$ is also the intercept of the equation. In other words, $\beta_0$ is the expected value of $primary\_06_i$, if $treatment_i = 0$ and $age_i = 0$. 
* $\beta_1$ is almost meaningless by itself. The only time it has meaning is when its value is connected to our intercept (i.e. $\beta_0 + \beta_1$). When the two are added together, you get the percentage voting for those in the treatment group, who on the day of election, have been alive for zero years of age.
* $\beta_2$ is, for the entire population, the average difference in $primary\_06_i$ between two individuals, one of whom has an $age_i$ value of 1 greater than the other. 

Let's translate the model into code. 

```{r, cache=TRUE}
model_3 <- stan_glm(data = ch9_sham, 
                 formula = primary_06 ~ treatment + age, 
                 refresh = 0)
```

```{r}
print(model_3, digits = 3)
```

The `(Intercept)` here is the intercept for the Control group, our baseline for comparison. The `(Intercept)` does have a mathematical interpretation, but it does not have a practical interpretation. Why is this? Because the slope for age starts at zero. This is nonsensical for our purposes, as no voter can be of zero age. 

Therefore, this model shows that, within the control group, the percent voting is `r round(coef(model_3)["(Intercept)"], 3)` times 100. 

How do we calculate our percent voting in the Neighbors group? Recall that the `treatmentNeighbors` median is not giving a standalone figure for this group, but rather represents the offset between the Control and Neighbors groups. To find the Neighbors value, we must add the offset to the original value: `r round(coef(model_3)["(Intercept)"] + coef(model_3)["treatmentNeighbors"], 3)`. This is nearly double the rate in the Control group!

Let's turn to our age median. Begin by grouping our observations by `age` and counting by `primary_06`, which gives us counts for 1 (yes) or 0 (no) for number voting in each age category. 

```{r}
age <- ch9_sham %>% 
  group_by(age) %>% 
  count(primary_06) 

age
```

To explore this relationship visually, let's create a graph. We are coercing `primary_06` into a character variable as it more closely represents "yes" or "no" as opposed to a numeric value. 

```{r}
age %>% 
  mutate(primary_06 = as.character(primary_06)) %>% 
  ggplot(aes(x = age, y = n, color = primary_06)) +
  geom_point() +
  labs(
    title = "Relationship Between Age and Voting",
    subtitle = "In the 2006 Primary Elections",
    x = "Age",
    y = "Count",
    color = "Did they vote?",
    caption = "1 = yes, 0 = no"
  )
```

There are some interesting takeaways here. 
- First, in almost every age bracket (other than above 90), the majority participants did *not* vote. 
- The spike between ages 40 and 60 illustrates that most participants exist in this age bracket. 
- The differences between voters and non-voters narrows greatly after age 60.

Let's now look at another graph that aims to show the same phenomena, but also includes a formula using `lm`. This more clearly shows the upward trend in voting as a participants age increases. We can also see that the highest concentrations in the "Voted" row exist from ages 45-50, whereas the highest concentrations for the "Did Not Vote" row exist in the 18-25 and 30-60 age groups. Again, we see that, for almost all ages, the partcipants are more likely to not vote than vote. This is illustrated by the darker concentration of dots in the "Did Not Vote" row. The slope of our regression line, however, shows a clear picture: the older you are, the more likely you are to vote. 

```{r}
shaming %>% 
  ggplot(aes(age, primary_06)) + 
  geom_jitter(alpha = 0.005, height = 0.1) + 
  geom_smooth(formula = y ~ x, method = "lm", se = FALSE) + 
  scale_y_continuous(breaks = c(0, 1), labels = c("Did Not Vote", "Voted")) + 
  labs(title = "Age and Voting in 2012 Michigan Primary Election", 
       subtitle = "Older people are more likely to vote", 
       x = "Age", 
       y = NULL, 
       caption = "Data from Gerber, Green, and Larimer (2008)") 
```

Note that the median for age is `r round(coef(model_3)["age"], 3)`. Age is therefore positively correlated with voting in the primary election. What does that mean? It means that, for every year that a participant's age increases, their odds of voting in the primary *increases* by `r round(coef(model_3)["age"], 3)`. Now, this might not seem like a huge difference. However, think of it like this: for every decade older that a participant is, their odds of voting increase `r round((coef(model_3)["age"] * 10), 1)` %! This makes sense considering that we just learned that older citizens are more likely to vote. 

Now, let's return to our voting difference between the Control and Neighbors groups. Let's model the posterior probability distribution for the rates of voting. 

```{r} 
model_3 %>%  
  as_tibble() %>%  
  mutate(Neighbors = `(Intercept)` + `treatmentNeighbors`) %>%
  mutate(Control = `(Intercept)`) %>%  
  select(Neighbors, Control) %>% 
  pivot_longer(cols = Neighbors:Control, 
               names_to = "parameters", 
               values_to = "percent_voting") %>%  
  ggplot(aes(percent_voting, fill = parameters)) + 
    geom_histogram(aes(y = after_stat(count/sum(count))), 
                   alpha = 0.5,  
                   bins = 100,  
                   position = "identity") + 
    labs(title = "Posterior Probability Distribution", 
         subtitle = "for Control versus Neighbors voting rates", 
        x = "% of group voting", 
        y = "Probability") +  
   scale_x_continuous(labels = scales::percent_format()) + 
   scale_y_continuous(labels = scales::percent_format()) + 
   theme_classic() 
```

This is interesting. Here, we can see that the difference between the expected voting behavior between Control and Neighbors is meaningful. There is only a very small overlap where it is more likely for those in Control to vote when compared with those in the treatment group. This bodes well for our election, as we see that the treatment makes a large difference.

However, there is one caveat to this plot: it is the posterior for those with voting age zero, which is nonsense! Is this helpful for *our* election? Not really, since our voters are likely to be... well, not zero years old. 

Let's modify `age` to be the average age for the dataset. We will use the mean of election_age, which is about `r round(mean(ch9_sham$age), 0)`. Once we find this number, we will subtract it from every `age` value, creating a new variable: `c_age`, where the “c” stand for centered. `c_age` is the number of years a voter has been alive, as of Election Day, relative to the average years alive of all voters on election day.

```{r}
ch9_sham <- ch9_sham %>% 
  mutate(c_age = age - mean(age))
```

Create our model: 

```{r, cache=TRUE}
model_4 <- stan_glm(data = ch9_sham, 
                 formula = primary_06 ~ treatment + c_age, 
                 refresh = 0)
```

Look at results: 

```{r}
print(model_4, digits = 3)
```

Now that we have a more sensible value for age, let's create the posterior:

```{r} 
model_4 %>%  
  as_tibble() %>%  
  mutate(Neighbors = `(Intercept)` + `treatmentNeighbors`) %>%
  mutate(Control = `(Intercept)`) %>%  
  select(Neighbors, Control) %>% 
  pivot_longer(cols = Neighbors:Control, 
               names_to = "parameters", 
               values_to = "percent_voting") %>%  
  ggplot(aes(percent_voting, fill = parameters)) + 
    geom_histogram(aes(y = after_stat(count/sum(count))), 
                   alpha = 0.5,  
                   bins = 100,  
                   position = "identity") + 
    labs(title = "Posterior Probability Distribution", 
         subtitle = "for Control versus Neighbors voting rates", 
        x = "% of group voting", 
        y = "Probability") +  
   scale_x_continuous(labels = scales::percent_format()) + 
   scale_y_continuous(labels = scales::percent_format()) + 
   theme_classic() 
```

As we can see, this plot is quite different! This plot is showing, rather than the posterior for age 0, the posterior for the average age in the dataset, which is about `r round(mean(ch9_sham$age), 0)`. In this example, where `c_age` is more meaningful, the difference between the estimates for percent voting within `Control` and `Neighbors` is even greater. In fact, there is no overlap between the groups. According to this model, we would *never* expect for someone in the `Control` group to be more likely to vote than someone in the `Neighbors` group. 


### primary_06 ~ age + solo + treatment + solo*treatment

It is time to look at interactions! Here, we will look at `primary_06` as a function of `c_age`, `solo`, `treatment`, and `solo*treatment`. What does `solo*treatment` mean for us? It means we are looking at the `solo` and `treatment` variables as they correspond to one another. 

```{r, cache=TRUE}
model_5 <- stan_glm(data = ch9_sham, 
                 formula = primary_06 ~ c_age + solo + treatment + solo * treatment, 
                 refresh = 0)
```

```{r}
print(model_5, digits = 3)
```

<!-- There is lots to look at here. Let's narrow our focus a bit to highlight some important takeaways. First, our baseline is again: female participants in multi-person households under treatment Civic Duty. For this group, the (Intercept) is 0.304 = 30.4% voting. Every other variable represents an offset from that baseline value. Let's dig in!

First, note that (as we saw in the last model) sexMale and soloTRUE both *increase* the odds of a participant voting. The median values represent an offset from baseline. Therefore, the true value for sexMale would be the (Intercept) + sexMale = 0.304 + 0.022 = 0.326. The true value for soloTRUE is (Intercept) + soloTRUE = 0.304 + 0.068 = 0.372. 

Note that all treatments increase voter turnout in the female, multi-person household group. The Control group observes a *decrease* in voter turnout. 

Now, we will turn out attention to our interactions. 
- `soloTRUE: treatmentHawthorne` is showing us the offset in voter turnout (intercept) for female people who live in single voter households under treatmentHawthorne as compared to our baseline of treatment Civic Duty. The median of -0.086 represents an offset from the soloTRUE group. We must take the soloTRUE intercept value previously calculated (0.372) and add this to `soloTRUE:treatmentHawthorne` to show the difference in values: 0.372 + (-0.086) = .286. This number represents that, within the overall `soloTRUE` group under, `treatmentHawthorne` showed *less* voter turnout than the Civic Duty group itself. 
- `soloTRUE:treatmentControl` looks at the offset from our baseline in female, single person households under the control treatment. With a median of -0.029, this means that our intercept for this group would be 0.372 (`soloTRUE`) + -0.029 (`soloTRUE:treatmentControl`) = 0.343. As compared with the Civic Duty treatment, those participants in single person households voted *less* under the Control group. 
- `soloTRUE:treatmentSelf` shows the offset from our baseline under the Self treatment. The intercept for this group would be the soloTRUE intercept + the interaction value = 0.372 + 0.003 = 0.375. This shows that, compared with our baseline of soloTRUE under the Civic Duty treatment, the voter turnout for this group is *slightly increased*. 
- `soloTRUE:treatmentNeighbors` shows the offset from our baseline under the Neighbors treatment. Again, to find the true intercept, we must add this interaction value of 0.006 to our calculated soloTRUE intercept: 0.372 + 0.006 = 0.378. Therefore, compared to the solo group under treatment Civic Duty, the solo group under treatment Neighbors *voted more*. 

What does this tell us? First, we know that (of the various treatments) Neighbors continues to be the most effective, even in those female citizens that are living alone. We also know that, in those females living alone, the control and Hawthorne treatment are less effective as compared with the Civic Duty treatment. And, while the Self and Neighbors treatments *did* increase voter turnout, the rate of increase was less as compared to the soloFALSE group (showed in the previous model). -->

## Temperance

```{r echo = FALSE, fig.cap = "Temperance"}
knitr::include_graphics("other/images/Temperance.jpg")
```

Finally, let's remember the virtue of Temperance. The gist of temperance is: be humble with our inferences, as our inferences are always, certainly, and unfortunately not going to match the real world. How does this apply to our shaming scenario?

Prediction uncertainty is the main culprit. No matter how hard we try, *we cannot predict the future*. Though we now have conclusions about how shaming impacted voters in the 2006 primary elections, we do not have the confidence to say that what worked or didn't work then would work now. 

For instance, perhaps the impact of your neighbors knowing your voting history is greater in the midst of a pandemic, where you may be locked inside with few interactions outside of your immediate proximity. Perhaps the opposite is true. These *unknown unknowns* cannot be accounted for in our models. We cannot predict a pandemic, nor can we predict how this will change the way that people vote or respond to fliers. 

There is also the issue of representativeness. Do the voters of the 2006 primary election (who have already demonstrated a willingness to vote in the 2004 primary election) truly represent the people voting in **our** gubernatorial election? 

These complications are why we must make inferences with a grain of salt. That is not to say that all data science is unhelpful! On the contrary, acknowledging our deficits will only make our inferences (and the actions we take because of them) stronger. 

<!-- What we need to add: Preceptor table, causal explanation, math before models, posterior_epred. -->

## Summary

*Key commands*:
* Use the `tidy()` function from the **broom.mixed** package to make models with $N$ parameters easier to interpret. 
* A function we are familiar with, `stan_glm()`, is used to create models with $N$ parameters. 

*Remember*:
* It is important to remember that the data does not equal the truth. For instance, in regards to our first model, we do not expect a governor elected in Delaware to live significantly longer than a governor in Wyoming.
* The population we would like to make inferences about *is not the population for which we have data*. It is a matter of wisdom whether the data we do have maps closely enough to the population we are studying.
* When dealing with models with many parameters, double check that you know how to find the true slope and intercepts --- often, this requires adding numerous values to the coefficient you are studying. 
